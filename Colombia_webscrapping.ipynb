{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytest in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (8.3.3)\n",
      "Requirement already satisfied: iniconfig in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pytest) (2.0.0)\n",
      "Requirement already satisfied: packaging in /Users/alexa/Library/Python/3.11/lib/python/site-packages (from pytest) (23.1)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pytest) (1.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_path = '/Users/alexa/Projects/QoL/chromedriver-mac-arm64/chromedriver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# Configuración del ChromeDriver\n",
    "service = Service(driver_path)  # Cambia esto por la ruta de tu ChromeDriver\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "try:\n",
    "    # URL de la página\n",
    "    url = \"https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Decretos/30019893\"\n",
    "    \n",
    "    # Abrir la página\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Esperar a que el cuerpo de la página esté presente\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
    "    )\n",
    "    \n",
    "    # Obtener el HTML de la página\n",
    "    \n",
    "    page_source = driver.page_source\n",
    "    # Mostrar una parte del contenido en la consola\n",
    "    print(\"\\nRaw HTML Sample:\\n\")\n",
    "    print(page_source[0:19000])  # Muestra solo una parte del HTML\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "finally:\n",
    "    # Cerrar el navegador\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Raw HTML Sample:\n",
      "\n",
      "ttom: 0;\n",
      "      \tmargin-top: 0;\n",
      "      \tpadding-bottom: 0;\n",
      "      \tpadding-top: 0;\n",
      "      \tline-height: 130%;\n",
      "      \tcolor: #000000;\n",
      "      \tfont-weight: normal;\n",
      "      \tbackground-color: transparent;\n",
      "      }\n",
      "\n",
      "  .documento_cms li{\n",
      "      \tfont-family: Arial, Helvetica, sans-serif;\n",
      "      \tfont-size: 14px;\n",
      "      \tmargin-bottom: 0;\n",
      "      \tmargin-top: 0;\n",
      "      \tpadding-bottom: 0;\n",
      "      \tpadding-top: 0;\n",
      "      \tline-height: 130%;\n",
      "      \tcolor: #000000;\n",
      "      \tfont-weight: normal;\n",
      "      \tbackground-color: transparent;\n",
      "      }\n",
      "\n",
      "      .documento_cms .articulo-parrafo{\n",
      "      \tfont-weight: bold;\n",
      "      }\n",
      "      .documento_cms .titulo-centrado{\n",
      "      \tfont-weight: bold;\n",
      "      \ttext-align:center;\n",
      "      }\n",
      "      .documento_cms .division{\n",
      "      \ttext-align:center;\n",
      "      \tmargin-top: 20px;\n",
      "      \tmargin-bottom: 20px;\n",
      "      }\n",
      "      .documento_cms .titulo-anexo{\n",
      "      \ttext-align:center;\n",
      "      \tmargin-top: 20px;\n",
      "      }\n",
      "      .documento_cms .parrafo-division {\n",
      "      \tfont-weight: bold;\n",
      "      \tfont-size: 15px;\n",
      "      }\n",
      "      .documento_cms .parrafo-comun {\n",
      "      \tmargin-top: 4px;\n",
      "      }\n",
      "      .documento_cms .indented\n",
      "      {\n",
      "      \tpadding-left: 15pt;\n",
      "      \tpadding-right: 15pt;\n",
      "      }\n",
      "      .documento_cms table\n",
      "      {\n",
      "      \tmargin-bottom: 5px;\n",
      "      }\n",
      "      .documento_cms .toc\n",
      "      {\n",
      "      \tbackground-color:#F9F9F9;\n",
      "      \tborder:1px solid #AAAAAA;\n",
      "      \tfont-size:95%;\n",
      "      \tpadding:7px;\n",
      "      }\n",
      "\n",
      "      .documento_cms .toctitle\n",
      "      {\n",
      "      \ttext-align:center;\n",
      "      \talign:center;\n",
      "      }\n",
      "\n",
      "      .documento_cms li.vinieta-toc\n",
      "      {\n",
      "      \tlist-style-type: none;\n",
      "      }\n",
      "\n",
      "      .documento_cms ul.lista-toc\n",
      "      {\n",
      "      \tmargin-left: 25px;\n",
      "      }\n",
      "\n",
      "      .documento_cms ul.resumenvigencias\n",
      "      {\n",
      "      \tmargin-bottom: 12px;\n",
      "        list-style-type: none;\n",
      "      }\n",
      "      .documento_cms li.resumenvigencias\n",
      "      {\n",
      "      \tmargin-top: 12px;\n",
      "        list-style-type: none;\n",
      "      }\n",
      "      .documento_cms li.referencia\n",
      "      {\n",
      "      \tmargin-top: 6px;\n",
      "      }\n",
      "      .documento_cms .titulo\n",
      "      {\n",
      "      \tmargin-top: 5px;\n",
      "      \tfont-weight: bold;\n",
      "      }\n",
      "      .centrado{text-align:center}\n",
      "      .centrado_margen_der_0punto5{text-align:center;margin-right:0.5cm}\n",
      "      .centrado_margen_der_1punto0{text-align:center;margin-right:1cm}\n",
      "      .centrado_margen_der_2punto0{text-align:center;margin-right:2cm}\n",
      "      .centrado_margen_der_3punto0{text-align:center;margin-right:3cm}.centrado_margen_der_4punto0{text-align:center;margin-right:4cm}.centrado_margen_izq_0punto5{text-align:center;margin-left:0.5cm}.centrado_margen_izq_1punto0{text-align:center;margin-left:1cm}.centrado_margen_izq_2punto0{text-align:center;margin-left:2cm}.centrado_margen_izq_3punto0{text-align:center;margin-left:3cm}.centrado_margen_izq_4punto0{text-align:center;margin-left:4cm}.centrado_margen_izq_5punto0{text-align:center;margin-left:5cm}.centrado_margen_izq_6punto0{text-align:center;margin-left:6cm}.centrado_margen_izq_7punto0{text-align:center;margin-left:7cm}.indent_fl_1punto5{text-indent:1.5cm}.margen_der_0punto5{margin-right:0.5cm}.margen_der_1punto0{margin-right:1cm}.margen_der_2punto0{margin-right:2cm}.margen_der_3punto0{margin-right:3cm}.margen_der_4punto0{margin-right:4cm}.margen_izq_0punto5{margin-left:0.5cm}.margen_izq_0punto5_margen_der_0punto5{margin-left:0.5cm;margin-right:0.5cm}.margen_izq_0punto5_margen_der_1punto0{margin-left:0.5cm;margin-right:1cm}.margen_izq_1punto0{margin-left:1cm}.margen_izq_1punto0_indent_fl_1punto5{margin-left:1cm;text-indent:1.5cm}.margen_izq_1punto0_margen_der_1punto0{margin-left:1cm;margin-right:1cm}.margen_izq_1punto0_margen_der_1punto0_indent_fl_1punto5{margin-left:1cm;margin-right:1cm;text-indent:1.5cm}.margen_izq_2punto0{margin-left:2cm}.margen_izq_2punto0_indent_fl_1punto5{margin-left:2cm;text-indent:1.5cm}.margen_izq_3punto0{margin-left:3cm}.margen_izq_3punto0_indent_fl_1punto5{margin-left:3cm;text-indent:1.5cm}.margen_izq_4punto0{margin-left:4cm}.margen_izq_4punto0_indent_fl_1punto5{margin-left:4cm;text-indent:1.5cm}.margen_izq_5punto0{margin-left:5cm}.margen_izq_5punto0_indent_fl_1punto5{margin-left:5cm;text-indent:1.5cm}.margen_izq_6punto0{margin-left:6cm}.margen_izq_7punto0{margin-left:7cm}.margen_izq_7punto0_indent_fl_1punto5{margin-left:7cm;text-indent:1.5cm}.margen_izq_7punto0_margen_der_4punto0{margin-left:7cm;margin-right:4cm}\n",
      "    \t</style></head><body class=\"documento_cms\"><header><nav><div style=\"display: flex; background-color:#fff; justify-content: center;\"><a href=\"http://www.suin-juriscol.gov.co/\" target=\"_blank\" title=\"Enlace para ir al portal Suin-Juriscol\"><img src=\"/imagenes/logos/logo_izq.png\" alt=\"Logo Suin-Juriscol\"></a><a href=\"http://www.minjusticia.gov.co/\" target=\"_blank\" title=\"Enlace para ir al portal Ministerio de Justicia y del Derecho\"><img src=\"/imagenes/logos/LogoMinjusticia2024.jpg\" alt=\"Logo minjusticia\"></a></div><ul><li><img width=\"50px\" height=\"50px\" src=\"/imagenes/logos/inicio.png\" alt=\"Inicio\"><b><a href=\"https://www.suin-juriscol.gov.co/\" title=\"Enlace para ir al portal SUIN-Juriscol\">Ir al portal SUIN-Juriscol</a></b></li><li><img width=\"50px\" height=\"50px\" src=\"/imagenes/logos/ayudar.png\" alt=\"Ayuda\"><b><a href=\"https://forms.office.com/r/Rc2jCP6iX0\" title=\"Enlace para ir al formulario Observaciones\" target=\"_blank\">Ayúdanos a mejorar</a></b></li><li><img width=\"50px\" height=\"50px\" src=\"/imagenes/logos/imprimir.png\" alt=\"Imprimir\"><b><a href=\"#\" onclick=\"window.print()\" title=\"Enlace para guardar o imprimir este documento\">Guardar en PDF o imprimir la norma</a></b></li><li><img width=\"50px\" height=\"50px\" src=\"/imagenes/logos/encuesta.png\" alt=\"Encuesta\"><b><a href=\"https://forms.office.com/pages/responsepage.aspx?id=zfse-ze-OEKE0k-sLHVR3K8uzJ3c1ntMoO87w5C1KZ5UMzE4OEpMOUVVWjQ2TUxNS1YyQ0NKRlFDNC4u\" title=\"Enlace para ir al formulario de encuesta\">Responder Encuesta</a></b></li></ul></nav></header><br><a name=\"arriba\"></a><div style=\"visibility:hidden; height: 0;\"><span field=\"tipo\">DECRETO</span><span field=\"numero\">1084</span><span field=\"anio\">2015</span><span field=\"fecha\">201505\n",
      "script\n",
      "var date = new Date(26/05/2015); document.write(date.getDate());\n",
      "script\n",
      "</span><span field=\"descriptores\"></span><span field=\"division_documento\">false</span><span field=\"es_reglamento\">false</span><span field=\"documento_fuente\">DIARIO OFICIAL. AÑO CLI. N. 49523. 26, MAYO, 2015. PAG. 1642.</span><span field=\"entidad_emisora\">DEPARTAMENTO ADMINISTRATIVO PARA LA PROSPERIDAD SOCIAL</span><span field=\"epigrafe\">por medio del cual se expide el Decreto Único Reglamentario del Sector de Inclusión  Social y Reconciliación.</span><span field=\"estado_documento\">Vigente</span><span field=\"estado_excepcion\">false</span><span field=\"tema\">Decreto Unico Reglamentario</span><span field=\"titulo_uniforme\"></span><span field=\"es_codigo\">false</span><span field=\"sector\">Inclusión Social y Reconciliación</span><span field=\"marco_regulatorio\">false</span><span field=\"materia\">Protección Social</span><span field=\"en_estudio_depuracion\">false</span><span field=\"subtipo\">DECRETO ÚNICO</span><span field=\"Estatutos\"></span><span field=\"asunto\"></span><span field=\"comentarios\"></span><span field=\"de\"></span><span field=\"documento_fuente2\"></span><span field=\"es_estatuto\">false</span><span field=\"fe_de_erratas\"></span><span field=\"fecha_diario_oficial\">26/05/2015</span><span field=\"fecha_diario_oficial2\"></span><span field=\"fecha_expedicion\">26/05/2015</span><span field=\"fecha_fin_vigencia\"></span><span field=\"fecha_vigencia\">26/05/2015</span><span field=\"juris_estado_excepcion\"></span><span field=\"lugar_fecha\"></span><span field=\"nombre_codigo\"></span><span field=\"notas_vigencias\"></span><span field=\"numero_diario_oficial\">49523</span><span field=\"numero_diario_oficial2\"></span><span field=\"observaciones\"></span><span field=\"observaciones_internas\"></span><span field=\"pagina_diario_oficial\">1642</span><span field=\"pagina_diario_oficial2\"></span><span field=\"pagina_diario_oficial_pdf\">1642</span><span field=\"para\"></span><span field=\"separacion_numero\"></span></div><p>DIARIO OFICIAL. AÑO CLI. N. 49523. 26, MAYO, 2015. PAG. 1642.</p><table id=\"toc\" class=\"toc\" style=\"width: 100%; margin-top: 10px\"><tbody><tr><td><div id=\"toctitle\"><p style=\"font-weight:bold; margin-left: 0px;\"><span style=\"letter-spacing: 3px;\">ÍNDICE </span><span class=\"toctoggle\">[<a href=\"#\" class=\"toc-link\" id=\"togglelink\" onclick=\"toggle_visibility('30019893cuerpo-toc','togglelink'); return false;\">Mostrar</a>]</span></p></div><div style=\"display: none;\" id=\"30019893cuerpo-toc\"><ul class=\"lista-toc\"><li class=\"vinieta-toc\"><p><b><a onclick=\"return false;\" href=\"#ver_30048835\"><span class=\"toctext\">LIBRO 1</span></a></b></p></li><li class=\"vinieta-toc\"><p><b><a onclick=\"return false;\" href=\"#ver_30048835\"><span class=\"toctext\"></span></a></b></p></li><li class=\"vinieta-toc\"><p><b><a onclick=\"return false;\" href=\"#ver_30048835\"><span class=\"toctext\">Estructura del Sector de Inclusión Social y Reconciliación</span></a></b></p></li><li class=\"vinieta-toc\"><p><b><a onclick=\"return false;\" href=\"#ver_30048835\"><span class=\"toctext\"></span></a></b></p></li><li class=\"vinieta-toc\"><p><b><a onclick=\"return false;\" href=\"#ver_30048835\"><span class=\"toctext\">PARTE 1</span></a></b></p></li><li class=\"vinieta-toc\"><p><b><a onclick=\"return false;\" href=\"#ver_30048835\"><span class=\"toctext\"></span></a></b></p></li><li class=\"vinieta-toc\"><p><b><a onclick=\"return false;\" href=\"#ver_30048835\"><span class=\"toctext\">Sector Central</span></a></b></p></li><li class=\"vinieta-toc\"><p><b><a onclick=\"return false;\" href=\"#ver_30048835\"><span class=\"toctext\"></span></a></b></p></li><li class=\"vinieta-toc\"><p><b><a onclick=\"return false;\" href=\"#ver_30048835\"><span class=\"toctext\">TÍTULO 1</span></a></b></p></li><li class=\"vinieta-toc\"><p><b><a onclick=\"return false;\" href=\"#ver_30048835\"><span class=\"toctext\"></span></a></b></p></li><li class=\"vinieta-toc\"><p><b><a onclick=\"return false;\" href=\"#ver_30048835\"><span class=\"toctext\">Cabeza del sector</span></a></b></p></li><p class=\"indented\"\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "\n",
    "# Configure WebDriver\n",
    "chrome_options = Options()\n",
    "#chrome_options.add_argument('--headless')  # Run in headless mode (no GUI)\n",
    "chrome_service = Service(driver_path)  # Replace with your chromedriver path\n",
    "\n",
    "# Initialize WebDriver\n",
    "driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n",
    "\n",
    "# Load the page\n",
    "url = \"https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Decretos/30019893\"\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the content to load (you may need to adjust the sleep time)\n",
    "time.sleep(10)\n",
    "\n",
    "# Print a portion of the page source to inspect\n",
    "page_source = driver.page_source\n",
    "print(\"\\nRaw HTML Sample:\\n\")\n",
    "print(page_source[9000:19000])  # Print a snippet for inspection\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "# Configure Selenium WebDriver\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Run in headless mode (disable for debugging)\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\n",
    "    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    ")\n",
    "\n",
    "service = Service(driver_path)  # Replace with the correct path\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "try:\n",
    "    # Load the webpage\n",
    "    url = \"https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Decretos/30019893\"\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the page to load completely\n",
    "    time.sleep(10)  # Adjust the sleep time if needed\n",
    "\n",
    "    # Find elements with IDs starting with 'toggle_'\n",
    "    toggle_elements = driver.find_elements(By.XPATH, \"//*[starts-with(@id, 'toggle_')]\")\n",
    "    print(f\"Found {len(toggle_elements)} elements.\")\n",
    "\n",
    "    # Save the content to a list\n",
    "    results = []\n",
    "    for element in toggle_elements:\n",
    "        print(f\"Element text: {element.text}\")  # Debug print\n",
    "        results.append(element.text)\n",
    "\n",
    "    # Write the results to a file\n",
    "    with open('output.txt', 'w', encoding='utf-8') as file:\n",
    "        for result in results:\n",
    "            file.write(result + '\\n')\n",
    "\n",
    "    print(\"Results saved to output.txt\")\n",
    "\n",
    "finally:\n",
    "    # Quit the driver\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Decreto 1074 de 2015 Sector Comercio, Industria y Turismo (https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Decretos/30019935)\n",
      "Found 4440 elements.\n",
      "Results saved to Decreto 1074 de 2015 Sector Comercio_ Industria y Turismo.txt\n",
      "Processing: Decreto 1077 de 2015 Sector Vivienda, Ciudad y Territorio (https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Decretos/30020036)\n",
      "Found 3487 elements.\n",
      "Results saved to Decreto 1077 de 2015 Sector Vivienda_ Ciudad y Territorio.txt\n",
      "Processing: Decreto 1076 de 2015 Sector Ambiente y Desarrollo Sostenible (https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Decretos/30019960)\n",
      "Found 4000 elements.\n",
      "Results saved to Decreto 1076 de 2015 Sector Ambiente y Desarrollo Sostenible.txt\n",
      "Processing: Decreto 780 de 2016 Sector Salud y Protección Social (https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Decretos/30021559)\n",
      "Found 4528 elements.\n",
      "Results saved to Decreto 780 de 2016 Sector Salud y Protección Social.txt\n",
      "Processing: DECRETO 1075 DE 2015 Decreto Único Reglamentario del Sector Educación. (https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Decretos/30019930)\n",
      "Found 3840 elements.\n",
      "Results saved to DECRETO 1075 DE 2015 Decreto Único Reglamentario del Sector Educación..txt\n",
      "Processing: DECRETO 1080 DE 2015 Decreto Único Reglamentario del Sector Cultura. (https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Decretos/30019898)\n",
      "Found 1737 elements.\n",
      "Results saved to DECRETO 1080 DE 2015 Decreto Único Reglamentario del Sector Cultura..txt\n",
      "Processing: DECRETO 1085 DE 2015 Decreto Único Reglamentario del Sector Administrativo del Deporte. (https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Decretos/30019879)\n",
      "Found 562 elements.\n",
      "Results saved to DECRETO 1085 DE 2015 Decreto Único Reglamentario del Sector Administrativo del Deporte..txt\n",
      "Processing: DECRETO 1084 DE 2015 Decreto Único Reglamentario del Sector de Inclusión Social y Reconciliación. (https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Decretos/30019893)\n",
      "Found 1252 elements.\n",
      "Results saved to DECRETO 1084 DE 2015 Decreto Único Reglamentario del Sector de Inclusión Social y Reconciliación..txt\n",
      "Processing: CONSTITUCIÓN POLÍTICA 1991 (https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Constitucion/1687988)\n",
      "Found 1000 elements.\n",
      "Results saved to CONSTITUCIÓN POLÍTICA 1991.txt\n",
      "Processing: LEY 4 DE 1913 Sobre régimen político y municipal (https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Leyes/1820591)\n",
      "Found 680 elements.\n",
      "Results saved to LEY 4 DE 1913 Sobre régimen político y municipal.txt\n",
      "Processing: LEY 115 DE 1994 por la cual se expide la ley general de educación (https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Leyes/1645150)\n",
      "Found 444 elements.\n",
      "Results saved to LEY 115 DE 1994 por la cual se expide la ley general de educación.txt\n",
      "Processing: LEY 1801 DE 2016 por la cual se expide el Código Nacional de Seguridad y Convivencia Ciudadana. (https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Leyes/30021736)\n",
      "Found 499 elements.\n",
      "Results saved to LEY 1801 DE 2016 por la cual se expide el Código Nacional de Seguridad y Convivencia Ciudadana..txt\n",
      "Processing: LEY 100 DE 1993 Por la cual se crea el sistema de seguridad social integral y se dictan otras disposiciones (https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Leyes/1635955)\n",
      "Found 590 elements.\n",
      "Results saved to LEY 100 DE 1993 Por la cual se crea el sistema de seguridad social integral y se dictan otras disposiciones.txt\n",
      "Processing: DECRETO 1333 DE 1986 por el cual se expide el Código de Régimen Municipal (https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Decretos/1267982)\n",
      "Found 772 elements.\n",
      "Results saved to DECRETO 1333 DE 1986 por el cual se expide el Código de Régimen Municipal.txt\n",
      "Processing: LEY 1098 DE 2006 Por la cual se expide el Código de la Infancia y la Adolescencia. (https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Leyes/1673639)\n",
      "Found 436 elements.\n",
      "Results saved to LEY 1098 DE 2006 Por la cual se expide el Código de la Infancia y la Adolescencia..txt\n",
      "Processing: LEY 3 DE 1991 Por la cual se crea el Sistema Nacional de Vivienda de Interés Social, se establece el subsidio familiar de vivienda, se reforma el Instituto de Crédito Territorial, ICT, y se dictan otras disposiciones (https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Leyes/1558431)\n",
      "Found 90 elements.\n",
      "Results saved to LEY 3 DE 1991 Por la cual se crea el Sistema Nacional de Vivienda de Interés Social_ se establece el subsidio familiar de vivienda_ se reforma el Instituto de Crédito Territorial_ ICT_ y se dictan otras disposiciones.txt\n",
      "Processing: LEY 769 DE 2002 por la cual se expide el Código Nacional de Tránsito Terrestre y se dictan otras disposiciones. (https://www.suin-juriscol.gov.co/viewDocument.asp?ruta=Leyes/1826223)\n",
      "Found 361 elements.\n",
      "Results saved to LEY 769 DE 2002 por la cual se expide el Código Nacional de Tránsito Terrestre y se dictan otras disposiciones..txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "\n",
    "# Path to your CSV file\n",
    "csv_path = 'links_nacional.csv'  # Replace with the actual path to your CSV file\n",
    "\n",
    "# Path to ChromeDriver\n",
    "driver_path = driver_path  # Replace with your actual path\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Configure Selenium WebDriver\n",
    "chrome_options = Options()\n",
    "# Uncomment the line below to run in headless mode (disable it for debugging)\n",
    "# chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\n",
    "    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    ")\n",
    "service = Service(driver_path)\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "try:\n",
    "    # Loop through each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        document_name = row['name']  # Column with document names\n",
    "        url = row['link']  # Column with URLs\n",
    "        \n",
    "        # Sanitize the document name for use as a filename\n",
    "        sanitized_name = \"\".join(c if c.isalnum() or c in (' ', '.', '_') else '_' for c in document_name)\n",
    "        filename = f\"{sanitized_name}.txt\"\n",
    "\n",
    "        print(f\"Processing: {document_name} ({url})\")\n",
    "\n",
    "        # Load the webpage\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for the page to load completely\n",
    "        time.sleep(10)  # Adjust the sleep time if needed\n",
    "\n",
    "        # Find elements with IDs starting with 'toggle_'\n",
    "        toggle_elements = driver.find_elements(By.XPATH, \"//*[starts-with(@id, 'toggle_')]\")\n",
    "        print(f\"Found {len(toggle_elements)} elements.\")\n",
    "\n",
    "        # Save the content to a list\n",
    "        results = []\n",
    "        for element in toggle_elements:\n",
    "            results.append(element.text)\n",
    "\n",
    "        # Write the results to a file\n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            for result in results:\n",
    "                file.write(result + '\\n')\n",
    "\n",
    "        print(f\"Results saved to {filename}\")\n",
    "\n",
    "finally:\n",
    "    # Quit the driver\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora vamos a leer los archivos txt y hacer regex para comodar el texto \n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract articles from text\n",
    "def extract_articles_from_text(content):\n",
    "    # Define the regex pattern for matching articles and their text\n",
    "    pattern = r'((?:ART[ÍI]CULO|ARTlCULO)\\s\\d+(?:\\.\\d+)*\\.?)\\s*(.*?)(?=(?:\\n(?:ART[ÍI]CULO|ARTlCULO)\\s\\d+(?:\\.\\d+)*\\.?|$))'\n",
    "    # Find matches using the regex\n",
    "    matches = re.findall(pattern, content, re.DOTALL)\n",
    "\n",
    "    # Structure the data into a list of dictionaries\n",
    "    data = [{'Titulo': match[0].strip(),  # Article title\n",
    "             'Texto': match[1].strip()}   # Article text\n",
    "            for match in matches]\n",
    "\n",
    "    return data\n",
    "\n",
    "# Function to clean text and remove illegal characters for Excel\n",
    "def clean_text(text, max_length=32767):\n",
    "    # Remove illegal characters\n",
    "    text = ''.join(c for c in text if ord(c) >= 32 and ord(c) not in {0xFFFF, 0xFFFE})\n",
    "    return text[:max_length]  # Trim to Excel's maximum character limit\n",
    "\n",
    "# Function to save structured data to an Excel file\n",
    "def save_to_excel(data, output_file=\"structured_articles.xlsx\"):\n",
    "    # Clean data to remove illegal characters\n",
    "    cleaned_data = [{'Titulo': clean_text(item['Titulo']), \n",
    "                     'Texto': clean_text(item['Texto']),\n",
    "                     'Archivo': clean_text(item['Archivo'])} \n",
    "                    for item in data]\n",
    "    \n",
    "    # Convert data to a DataFrame\n",
    "    df = pd.DataFrame(cleaned_data)\n",
    "\n",
    "    # Save DataFrame to an Excel file\n",
    "    df.to_excel(output_file, index=False)\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "# Main process for processing all TXT files in a folder\n",
    "def process_all_txt_files_in_directory(input_directory, output_excel_file=\"structured_articles.xlsx\"):\n",
    "    all_data = []\n",
    "\n",
    "    # Loop through all TXT files in the directory\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            txt_path = os.path.join(input_directory, filename)\n",
    "            try:\n",
    "                print(f\"Processing file: {filename}\")\n",
    "                \n",
    "                # Read the content of the TXT file\n",
    "                with open(txt_path, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "                \n",
    "                # Extract articles from the text\n",
    "                articles_data = extract_articles_from_text(content)\n",
    "                \n",
    "                # Add file name to the data\n",
    "                for article in articles_data:\n",
    "                    article['Archivo'] = filename\n",
    "                \n",
    "                all_data.extend(articles_data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}. Skipping this file.\")\n",
    "\n",
    "    # Save all structured data to an Excel file\n",
    "    if all_data:\n",
    "        save_to_excel(all_data, output_excel_file)\n",
    "    else:\n",
    "        print(\"No data extracted from the TXT files. Excel file not created.\")\n",
    "\n",
    "# Run the main process\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"/Users/alexa/Projects/QoL/Cali/Colombia/nacional_txt/\"  # Replace with the folder containing your TXT files\n",
    "    output_file = \"structured_articles_nacional.xlsx\"\n",
    "    process_all_txt_files_in_directory(input_folder, output_file)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: Decreto 780 de 2016 Sector Salud y Protección Social.txt\n",
      "No data extracted from the TXT files. Excel file not created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Refined regex pattern\n",
    "# Updated Function to Extract Articles\n",
    "def extract_articles_from_text(content):\n",
    "    # Regex pattern to match articles with complex numbering\n",
    "    #pattern = r'((?:ART[ÍI]CULO|ARTlCULO)\\s\\d+(?:\\.\\d+)*\\.?)\\s*(.*?)(?=\\n(?:ART[ÍI]CULO|ARTlCULO)\\s\\d+(?:\\.\\d+)*\\.?|$)'\n",
    "    #pattern = r'((?:ART[ÍI]CULO|ARTlCULO)\\s\\d+(?:\\.\\d+)*(?:\\s*\\.\\d+)*\\.?)\\s*(.*?)(?=\\n(?:ART[ÍI]CULO|ARTlCULO)\\s\\d+(?:\\.\\d+)*(?:\\s*\\.\\d+)*\\.?|$)'\n",
    "    #pattern = r'(Artículo\\s\\d+[\\.°])\\s(.*?)(?=Artículo\\s\\d+[\\.°]|$)'\n",
    "    #pattern = r'(Artículo\\s[\\d\\.\\s]+)\\s(.*?)(?=Artículo\\s[\\d\\.\\s]+|$)'\n",
    "    pattern = r'^\\s*(Artículo\\s[\\d\\.°]+)\\s(.*?)(?=^\\s*Artículo\\s[\\d\\.°]+|\\Z)'\n",
    "    # Find matches using the regex\n",
    "    matches = re.findall(pattern, content, re.DOTALL)\n",
    "\n",
    "    # Structure the data into a list of dictionaries\n",
    "    data = [{'Titulo': match[0].strip(),  # Article title\n",
    "             'Texto': match[1].strip()}   # Article text\n",
    "            for match in matches]\n",
    "\n",
    "    return data\n",
    "\n",
    "# Function to clean text for Excel\n",
    "def clean_text(text, max_length=32767):\n",
    "    text = ''.join(c for c in text if ord(c) >= 32 and ord(c) not in {0xFFFF, 0xFFFE})\n",
    "    return text[:max_length]\n",
    "\n",
    "# Save results to Excel\n",
    "def save_to_excel(data, output_file=\"structured_articles.xlsx\"):\n",
    "    cleaned_data = [{'Titulo': clean_text(item['Titulo']), \n",
    "                     'Texto': clean_text(item['Texto']),\n",
    "                     'Archivo': clean_text(item['Archivo'])} \n",
    "                    for item in data]\n",
    "    df = pd.DataFrame(cleaned_data)\n",
    "    df.to_excel(output_file, index=False)\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "\n",
    "# Process TXT files\n",
    "def process_all_txt_files_in_directory(input_directory, output_excel_file=\"structured_articles.xlsx\"):\n",
    "    all_data = []\n",
    "\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            txt_path = os.path.join(input_directory, filename)\n",
    "            try:\n",
    "                print(f\"Processing file: {filename}\")\n",
    "                with open(txt_path, 'r', encoding='utf-8') as file:\n",
    "                    content = file.read()\n",
    "                articles_data = extract_articles_from_text(content)\n",
    "                for article in articles_data:\n",
    "                    article['Archivo'] = filename\n",
    "                all_data.extend(articles_data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}. Skipping this file.\")\n",
    "\n",
    "    if all_data:\n",
    "        save_to_excel(all_data, output_excel_file)\n",
    "    else:\n",
    "        print(\"No data extracted from the TXT files. Excel file not created.\")\n",
    "\n",
    "# Run the main process\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"/Users/alexa/Projects/QoL/Cali/Colombia/nacional_txt/decretos/\"  # Replace with your folder path\n",
    "    output_file = \"structured_articles_nacional.xlsx\"\n",
    "    process_all_txt_files_in_directory(input_folder, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Path to the uploaded file\n",
    "file_path = '/Users/alexa/Projects/QoL/Cali/Colombia/nacional_txt/decretos/Decreto 780 de 2016 Sector Salud y Protección Social.txt'\n",
    "\n",
    "def extract_articles_at_paragraph_start(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # Updated regex to match articles at the beginning of paragraphs\n",
    "    # Matches only if \"Artículo\" is at the start of a line\n",
    "    pattern = r'^\\s*(Artículo\\s[\\d\\.°]+)\\s(.*?)(?=^\\s*Artículo\\s[\\d\\.°]+|\\Z)'\n",
    "    \n",
    "    # Find all matches\n",
    "    articles = re.findall(pattern, text, re.DOTALL | re.MULTILINE)\n",
    "    \n",
    "    # Create a dictionary for better organization\n",
    "    article_dict = {}\n",
    "    for article, content in articles:\n",
    "        # Normalize article name\n",
    "        normalized_article = \" \".join(article.split())\n",
    "        # Clean up content\n",
    "        content = content.strip()\n",
    "        article_dict[normalized_article] = content\n",
    "    \n",
    "    return article_dict\n",
    "\n",
    "# Extract articles\n",
    "extracted_articles = extract_articles_at_paragraph_start(file_path)\n",
    "\n",
    "# Display extracted articles\n",
    "extracted_articles_list = [{\"Article\": article, \"Content\": content} for article, content in extracted_articles.items()]\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(extracted_articles_list)\n",
    "df.to_excel(\"Decreto_780.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF for PDF processing\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract text by page range\n",
    "def extract_text_by_page(pdf_path, page_range):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    extracted_text = \"\"\n",
    "    for page_num in page_range:\n",
    "        extracted_text += doc[page_num].get_text()\n",
    "    return extracted_text\n",
    "\n",
    "# Function to split text based on sections and pages\n",
    "def extract_sections_with_text(pdf_path, sections_with_pages):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    sections = {}\n",
    "    section_names = list(sections_with_pages.keys())\n",
    "    for i, section_name in enumerate(section_names):\n",
    "        start_page = sections_with_pages[section_name]\n",
    "        end_page = (\n",
    "            sections_with_pages[section_names[i + 1]]\n",
    "            if i + 1 < len(section_names)\n",
    "            else len(doc)\n",
    "        )\n",
    "        page_range = range(start_page, end_page)\n",
    "        sections[section_name] = extract_text_by_page(pdf_path, page_range).strip()\n",
    "    return sections\n",
    "\n",
    "# Save sections to Excel\n",
    "def save_sections_to_excel(sections, output_path):\n",
    "    data = [{\"Section Name\": name, \"Text\": text} for name, text in sections.items()]\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_excel(output_path, index=False)\n",
    "\n",
    "# Main function\n",
    "def process_pdf_with_index_dict(pdf_path, sections_with_pages, output_excel_path):\n",
    "    sections = extract_sections_with_text(pdf_path, sections_with_pages)\n",
    "    save_sections_to_excel(sections, output_excel_path)\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"strategic_plan.pdf\"  # Path to the PDF file\n",
    "sections_with_pages = {\n",
    "    \"INTRODUCCIÓN AL PLAN DE ACCIÓN\": 0,\n",
    "    \"OBJETIVO\": 1,\n",
    "    \"METODOLOGIA\": 1,\n",
    "    \"Los elementos del modelo conceptual de movilidad\": 2,\n",
    "    \"La selección de estrategias y programas\": 9,\n",
    "    \"El sistema de ponderación para la priorización en la selección de estrategias y programas\": 10,\n",
    "    # Add other sections and their corresponding page numbers\n",
    "    \"LAS DIRECTRICES GENERALES DE MOVILIDAD SOSTENIBLE EN SANTIAGO DE CALI\": 17,\n",
    "    \"PRINCIPIOS DE LAS DIRECTRICES\": 17,\n",
    "    \"OBJETIVOS DE LAS DIRECTRICES\": 17,\n",
    "    \"LA VISIÓN 2030 DEL PLAN INTEGRAL DE MOVILIDAD URBANA DE CALI\": 19,\n",
    "    \"OBJETIVO GENERAL DEL PIMU\": 19,\n",
    "}  # Replace with your complete dictionary of sections and pages\n",
    "\n",
    "output_excel_path = \"strategic_plan_sections.xlsx\"\n",
    "\n",
    "# Process the PDF\n",
    "process_pdf_with_index_dict(pdf_path, sections_with_pages, output_excel_path)\n",
    "\n",
    "print(f\"Sections saved to {output_excel_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Downloading PyMuPDF-1.24.14-cp39-abi3-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Downloading PyMuPDF-1.24.14-cp39-abi3-macosx_11_0_arm64.whl (18.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.4/18.4 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.24.14\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to structured_sections.xlsx\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Step 1: Read and save the entire text from the PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    full_text = \"\"\n",
    "    for page_num in range(len(doc)):\n",
    "        full_text += doc[page_num].get_text() + \"\\n\"\n",
    "    return full_text\n",
    "\n",
    "# Step 2: Identify sections in the text using regex\n",
    "def extract_sections_and_content(full_text):\n",
    "    # Define a regex pattern to match section titles based on their numbering structure\n",
    "    pattern = re.compile(r\"^(\\d+(\\.\\d+)*\\s+.*)$\", re.MULTILINE)  # Matches lines starting with numbers and a title\n",
    "    matches = pattern.finditer(full_text)\n",
    "\n",
    "    sections = []\n",
    "    positions = []\n",
    "\n",
    "    # Collect section titles and their positions in the text\n",
    "    for match in matches:\n",
    "        sections.append(match.group(1).strip())\n",
    "        positions.append(match.start())\n",
    "\n",
    "    # Step 3: Extract content for each section\n",
    "    structured_data = []\n",
    "    for i, section in enumerate(sections):\n",
    "        start_pos = positions[i]\n",
    "        end_pos = positions[i + 1] if i + 1 < len(positions) else len(full_text)\n",
    "        content = full_text[start_pos:end_pos].strip()\n",
    "        structured_data.append({\"Section Name\": section, \"Text\": content})\n",
    "\n",
    "    return structured_data\n",
    "\n",
    "# Step 4: Save structured data to an Excel file\n",
    "def save_to_excel(structured_data, output_path):\n",
    "    df = pd.DataFrame(structured_data)\n",
    "    df.to_excel(output_path, index=False)\n",
    "\n",
    "# Main function\n",
    "def main(pdf_path, output_excel_path):\n",
    "    # Extract text from the PDF\n",
    "    full_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    # Extract sections and their content\n",
    "    structured_data = extract_sections_and_content(full_text)\n",
    "\n",
    "    # Save to Excel\n",
    "    save_to_excel(structured_data, output_excel_path)\n",
    "    print(f\"Data saved to {output_excel_path}\")\n",
    "\n",
    "# Usage\n",
    "pdf_path = \"/Users/alexa/Projects/QoL/Cali/Cali/planes/Hidden_de Anexo1_Plan_de_Accion_PIMU (v.may-15-2019).pdf\"  # Replace with your PDF file path\n",
    "output_excel_path = \"structured_sections.xlsx\"\n",
    "main(pdf_path, output_excel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tika\n",
      "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tika) (65.5.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from tika) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->tika) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->tika) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->tika) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->tika) (2023.7.22)\n",
      "Building wheels for collected packages: tika\n",
      "  Building wheel for tika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32627 sha256=98e54d4c12d4a46cf36f4b6f5cfc354d7e6bc3126c2c5a30b7fcec5eb7d39125\n",
      "  Stored in directory: /Users/alexa/Library/Caches/pip/wheels/27/ba/2f/37420d1191bdae5e855d69b8e913673045bfd395cbd78ad697\n",
      "Successfully built tika\n",
      "Installing collected packages: tika\n",
      "Successfully installed tika-2.6.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to structured_sections.xlsx\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from tika import parser\n",
    "\n",
    "# Step 1: Extract text from PDF using Tika\n",
    "def extract_text_with_tika(pdf_path):\n",
    "    parsed_pdf = parser.from_file(pdf_path)  # Extract text\n",
    "    return parsed_pdf['content']  # Get content as string\n",
    "\n",
    "# Step 2: Identify sections in the text using regex\n",
    "def extract_sections_and_content(full_text):\n",
    "    # Define a regex pattern to match section titles with at least two levels\n",
    "    pattern = re.compile(r\"^\\d+\\.\\d+(\\.\\d+)*\\s+.*$\", re.MULTILINE)\n",
    "    matches = pattern.finditer(full_text)\n",
    "\n",
    "    sections = []\n",
    "    positions = []\n",
    "\n",
    "    # Collect section titles and their positions in the text\n",
    "    for match in matches:\n",
    "        sections.append(match.group(0).strip())\n",
    "        positions.append(match.start())\n",
    "\n",
    "    # Step 3: Extract content for each section\n",
    "    structured_data = []\n",
    "    for i, section in enumerate(sections):\n",
    "        start_pos = positions[i]\n",
    "        end_pos = positions[i + 1] if i + 1 < len(positions) else len(full_text)\n",
    "        content = full_text[start_pos:end_pos].strip()\n",
    "        structured_data.append({\"Section Name\": section, \"Text\": content})\n",
    "\n",
    "    return structured_data\n",
    "\n",
    "# Step 3: Save structured data to an Excel file\n",
    "def save_to_excel(structured_data, output_path):\n",
    "    df = pd.DataFrame(structured_data)\n",
    "    df.to_excel(output_path, index=False)\n",
    "\n",
    "# Main function\n",
    "def main(pdf_path, output_excel_path):\n",
    "    # Extract text from the PDF using Tika\n",
    "    full_text = extract_text_with_tika(pdf_path)\n",
    "\n",
    "    # Extract sections and their content\n",
    "    structured_data = extract_sections_and_content(full_text)\n",
    "\n",
    "    # Save to Excel\n",
    "    save_to_excel(structured_data, output_excel_path)\n",
    "    print(f\"Data saved to {output_excel_path}\")\n",
    "\n",
    "# Usage\n",
    "pdf_path = \"/Users/alexa/Projects/QoL/Cali/Cali/planes/Hidden_de Anexo1_Plan_de_Accion_PIMU (v.may-15-2019).pdf\"  # Replace with your PDF file path\n",
    "output_excel_path = \"structured_sections.xlsx\"\n",
    "main(pdf_path, output_excel_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
